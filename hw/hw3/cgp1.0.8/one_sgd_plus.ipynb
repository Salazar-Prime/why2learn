{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4f72be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Homework 3: Understanding CGP code and implementing SGD + Momentum \n",
    "Author: Varun Aggarwal\n",
    "Last Modified: 27 Jan 2022\n",
    "\"\"\"\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import sys\n",
    "import operator\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from ComputationalGraphPrimer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b33cc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Modified from one_neuron_classifier.py\n",
    "seed = 0           \n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3edfef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inherited class \n",
    "class cgpSuperCharged(ComputationalGraphPrimer):\n",
    "    def __init__(self, mu=0.0, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.mu = mu\n",
    "        self.step_hist = 0\n",
    "        \n",
    "    def backprop_and_update_params_one_neuron_model(self, y_error_avg, data_tuple_avg, deriv_sigmoid_avg):\n",
    "        \"\"\"\n",
    "            This function is copied over from \n",
    "            ComputationalGraphPrimer.py Version 1.0.8\n",
    "\n",
    "            Modifications:\n",
    "            -----------\n",
    "            -----------\n",
    "            -----------\n",
    "            -----------\n",
    "        \"\"\"\n",
    "        input_vars = self.independent_vars\n",
    "        vals_for_input_vars_dict =  dict(zip(input_vars, list(data_tuple_avg)))\n",
    "        vals_for_learnable_params = self.vals_for_learnable_params\n",
    "        \n",
    "        for i,param in enumerate(self.vals_for_learnable_params):\n",
    "            ## calculate the next step in the parameter hyperplane\n",
    "            \n",
    "            # representing in same notation as the HW text\n",
    "            g_tp1 = y_error_avg * vals_for_input_vars_dict[input_vars[i]] * deriv_sigmoid_avg \n",
    "            \n",
    "            step = self.mu*self.step_hist[i] + self.learning_rate*g_tp1   \n",
    "            self.vals_for_learnable_params[param] += step\n",
    "            \n",
    "            # update step_hist\n",
    "            self.step_hist[i] = step\n",
    "        \n",
    "        ## Bias momentum step\n",
    "        self.bias_hist = self.mu*self.bias_hist + self.learning_rate * y_error_avg * deriv_sigmoid_avg  \n",
    "        self.bias += self.bias_hist\n",
    "    \n",
    "    def run_training_loop_one_neuron_model(self, training_data):\n",
    "        \"\"\"\n",
    "        The training loop must first initialize the learnable parameters.  Remember, these are the \n",
    "        symbolic names in your input expressions for the neural layer that do not begin with the \n",
    "        letter 'x'.  In this case, we are initializing with random numbers from a uniform distribution \n",
    "        over the interval (0,1).\n",
    "        \"\"\"\n",
    "        self.vals_for_learnable_params = {param: random.uniform(0,1) for param in self.learnable_params}\n",
    "        self.bias = random.uniform(0,1)\n",
    "\n",
    "        class DataLoader:\n",
    "            \"\"\"\n",
    "            The data loader's job is to construct a batch of randomly chosen samples from the\n",
    "            training data.  But, obviously, it must first associate the class labels 0 and 1 with\n",
    "            the training data supplied to the constructor of the DataLoader.   NOTE:  The training\n",
    "            data is generated in the Examples script by calling 'cgp.gen_training_data()' in the\n",
    "            ****Utility Functions*** section of this file.  That function returns two normally\n",
    "            distributed set of number with different means and variances.  One is for key value '0'\n",
    "            and the other for the key value '1'.  The constructor of the DataLoader associated a'\n",
    "            class label with each sample separately.\n",
    "            \"\"\"\n",
    "            def __init__(self, training_data, batch_size):\n",
    "                self.training_data = training_data\n",
    "                self.batch_size = batch_size\n",
    "                self.class_0_samples = [(item, 0) for item in self.training_data[0]]\n",
    "                self.class_1_samples = [(item, 1) for item in self.training_data[1]]\n",
    "            def __len__(self):\n",
    "                return len(self.training_data[0]) + len(self.training_data[1])\n",
    "            def _getitem(self):    \n",
    "                cointoss = random.choice([0,1])\n",
    "                if cointoss == 0:\n",
    "                    return random.choice(self.class_0_samples)\n",
    "                else:\n",
    "                    return random.choice(self.class_1_samples)            \n",
    "            def getbatch(self):\n",
    "                batch_data,batch_labels = [],[]\n",
    "                maxval = 0.0\n",
    "                for _ in range(self.batch_size):\n",
    "                    item = self._getitem()\n",
    "                    if np.max(item[0]) > maxval: \n",
    "                        maxval = np.max(item[0])\n",
    "                    batch_data.append(item[0])\n",
    "                    batch_labels.append(item[1])\n",
    "                batch_data = [item/maxval for item in batch_data]                \n",
    "                batch = [batch_data, batch_labels]\n",
    "                return batch                \n",
    "\n",
    "        data_loader = DataLoader(training_data, batch_size=self.batch_size)\n",
    "        loss_running_record = []\n",
    "        i = 0\n",
    "        avg_loss_over_literations = 0.0\n",
    "        \n",
    "        # preparing varibles \n",
    "        self.step_hist = list(np.zeros(len(self.learnable_params)))\n",
    "        self.bias_hist = 0 \n",
    "        \n",
    "        for i in range(self.training_iterations):\n",
    "            data = data_loader.getbatch()\n",
    "            data_tuples = data[0]\n",
    "            class_labels = data[1]\n",
    "            y_preds, deriv_sigmoids =  self.forward_prop_one_neuron_model(data_tuples)\n",
    "            loss = sum([(abs(class_labels[i] - y_preds[i]))**2 for i in range(len(class_labels))])\n",
    "            loss_avg = loss / float(len(class_labels))\n",
    "            avg_loss_over_literations += loss_avg\n",
    "            if i%(self.display_loss_how_often) == 0: \n",
    "                avg_loss_over_literations /= self.display_loss_how_often\n",
    "                loss_running_record.append(avg_loss_over_literations)\n",
    "                print(\"[iter=%d]  loss = %.4f\" %  (i+1, avg_loss_over_literations))\n",
    "                avg_loss_over_literations = 0.0\n",
    "            y_errors = list(map(operator.sub, class_labels, y_preds))\n",
    "            y_error_avg = sum(y_errors) / float(len(class_labels))\n",
    "            deriv_sigmoid_avg = sum(deriv_sigmoids) / float(len(class_labels))\n",
    "            data_tuple_avg = [sum(x) for x in zip(*data_tuples)]\n",
    "            data_tuple_avg = list(map(operator.truediv, data_tuple_avg, \n",
    "                                     [float(len(class_labels))] * len(class_labels) ))\n",
    "            self.backprop_and_update_params_one_neuron_model(y_error_avg, data_tuple_avg, deriv_sigmoid_avg)\n",
    "        \n",
    "        return loss_running_record  \n",
    "        \n",
    "        \n",
    "cgp = cgpSuperCharged(\n",
    "       one_neuron_model = True,\n",
    "       expressions = ['xw=ab*xa+bc*xb+cd*xc+ac*xd'],\n",
    "       output_vars = ['xw'],\n",
    "       dataset_size = 5000,\n",
    "       learning_rate = 1e-3,\n",
    "#      learning_rate = 5 * 1e-2,\n",
    "       training_iterations = 40000,\n",
    "       batch_size = 8,\n",
    "       display_loss_how_often = 100,\n",
    "       debug = True,\n",
    "      )\n",
    "\n",
    "cgp_original = ComputationalGraphPrimer(\n",
    "       one_neuron_model = True,\n",
    "       expressions = ['xw=ab*xa+bc*xb+cd*xc+ac*xd'],\n",
    "       output_vars = ['xw'],\n",
    "       dataset_size = 5000,\n",
    "       learning_rate = 1e-3,\n",
    "#      learning_rate = 5 * 1e-2,\n",
    "       training_iterations = 40000,\n",
    "       batch_size = 8,\n",
    "       display_loss_how_often = 100,\n",
    "       debug = True,\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75655215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "all variables: {'xc', 'xd', 'xb', 'xa', 'xw'}\n",
      "\n",
      "\n",
      "learnable params: ['ab', 'bc', 'cd', 'ac']\n",
      "\n",
      "\n",
      "dependencies: {'xw': ['xa', 'xb', 'xc', 'xd']}\n",
      "\n",
      "\n",
      "expressions dict: {'xw': 'ab*xa+bc*xb+cd*xc+ac*xd'}\n",
      "\n",
      "\n",
      "independent vars: ['xc', 'xd', 'xb', 'xa']\n",
      "\n",
      "\n",
      "leads_to dictionary: {'xc': {'xw'}, 'xd': {'xw'}, 'xb': {'xw'}, 'xa': {'xw'}, 'xw': set()}\n",
      "[iter=1]  loss = 0.0036\n",
      "[iter=101]  loss = 0.2938\n",
      "[iter=201]  loss = 0.2986\n",
      "[iter=301]  loss = 0.3137\n",
      "[iter=401]  loss = 0.3148\n",
      "[iter=501]  loss = 0.2942\n",
      "[iter=601]  loss = 0.3006\n",
      "[iter=701]  loss = 0.3027\n",
      "[iter=801]  loss = 0.2971\n",
      "[iter=901]  loss = 0.3048\n",
      "[iter=1001]  loss = 0.3100\n",
      "[iter=1101]  loss = 0.3075\n",
      "[iter=1201]  loss = 0.2838\n",
      "[iter=1301]  loss = 0.2843\n",
      "[iter=1401]  loss = 0.2951\n",
      "[iter=1501]  loss = 0.3168\n",
      "[iter=1601]  loss = 0.2891\n",
      "[iter=1701]  loss = 0.2967\n",
      "[iter=1801]  loss = 0.2871\n",
      "[iter=1901]  loss = 0.2843\n",
      "[iter=2001]  loss = 0.2880\n",
      "[iter=2101]  loss = 0.2964\n",
      "[iter=2201]  loss = 0.2951\n",
      "[iter=2301]  loss = 0.2970\n",
      "[iter=2401]  loss = 0.2836\n",
      "[iter=2501]  loss = 0.2890\n",
      "[iter=2601]  loss = 0.2824\n",
      "[iter=2701]  loss = 0.2932\n",
      "[iter=2801]  loss = 0.2862\n",
      "[iter=2901]  loss = 0.2865\n",
      "[iter=3001]  loss = 0.2881\n",
      "[iter=3101]  loss = 0.2770\n",
      "[iter=3201]  loss = 0.2781\n",
      "[iter=3301]  loss = 0.2928\n",
      "[iter=3401]  loss = 0.2715\n",
      "[iter=3501]  loss = 0.2888\n",
      "[iter=3601]  loss = 0.2761\n",
      "[iter=3701]  loss = 0.2755\n",
      "[iter=3801]  loss = 0.2853\n",
      "[iter=3901]  loss = 0.2910\n",
      "[iter=4001]  loss = 0.2573\n",
      "[iter=4101]  loss = 0.2658\n",
      "[iter=4201]  loss = 0.2734\n",
      "[iter=4301]  loss = 0.2691\n",
      "[iter=4401]  loss = 0.2981\n",
      "[iter=4501]  loss = 0.2637\n",
      "[iter=4601]  loss = 0.2670\n",
      "[iter=4701]  loss = 0.2718\n",
      "[iter=4801]  loss = 0.2710\n",
      "[iter=4901]  loss = 0.2798\n",
      "[iter=5001]  loss = 0.2651\n",
      "[iter=5101]  loss = 0.2652\n",
      "[iter=5201]  loss = 0.2618\n",
      "[iter=5301]  loss = 0.2654\n",
      "[iter=5401]  loss = 0.2625\n",
      "[iter=5501]  loss = 0.2625\n",
      "[iter=5601]  loss = 0.2591\n",
      "[iter=5701]  loss = 0.2564\n",
      "[iter=5801]  loss = 0.2841\n",
      "[iter=5901]  loss = 0.2624\n",
      "[iter=6001]  loss = 0.2518\n",
      "[iter=6101]  loss = 0.2538\n",
      "[iter=6201]  loss = 0.2530\n",
      "[iter=6301]  loss = 0.2547\n",
      "[iter=6401]  loss = 0.2468\n",
      "[iter=6501]  loss = 0.2515\n",
      "[iter=6601]  loss = 0.2476\n",
      "[iter=6701]  loss = 0.2424\n",
      "[iter=6801]  loss = 0.2577\n",
      "[iter=6901]  loss = 0.2503\n",
      "[iter=7001]  loss = 0.2460\n",
      "[iter=7101]  loss = 0.2491\n",
      "[iter=7201]  loss = 0.2426\n",
      "[iter=7301]  loss = 0.2546\n",
      "[iter=7401]  loss = 0.2481\n",
      "[iter=7501]  loss = 0.2502\n",
      "[iter=7601]  loss = 0.2648\n",
      "[iter=7701]  loss = 0.2347\n",
      "[iter=7801]  loss = 0.2515\n",
      "[iter=7901]  loss = 0.2503\n",
      "[iter=8001]  loss = 0.2496\n",
      "[iter=8101]  loss = 0.2583\n",
      "[iter=8201]  loss = 0.2491\n",
      "[iter=8301]  loss = 0.2430\n",
      "[iter=8401]  loss = 0.2390\n",
      "[iter=8501]  loss = 0.2468\n",
      "[iter=8601]  loss = 0.2456\n",
      "[iter=8701]  loss = 0.2524\n",
      "[iter=8801]  loss = 0.2450\n",
      "[iter=8901]  loss = 0.2427\n",
      "[iter=9001]  loss = 0.2506\n",
      "[iter=9101]  loss = 0.2420\n",
      "[iter=9201]  loss = 0.2451\n",
      "[iter=9301]  loss = 0.2434\n",
      "[iter=9401]  loss = 0.2439\n",
      "[iter=9501]  loss = 0.2343\n",
      "[iter=9601]  loss = 0.2441\n",
      "[iter=9701]  loss = 0.2453\n",
      "[iter=9801]  loss = 0.2392\n",
      "[iter=9901]  loss = 0.2368\n",
      "[iter=10001]  loss = 0.2379\n",
      "[iter=10101]  loss = 0.2421\n",
      "[iter=10201]  loss = 0.2361\n",
      "[iter=10301]  loss = 0.2463\n",
      "[iter=10401]  loss = 0.2304\n",
      "[iter=10501]  loss = 0.2420\n",
      "[iter=10601]  loss = 0.2362\n",
      "[iter=10701]  loss = 0.2405\n",
      "[iter=10801]  loss = 0.2378\n",
      "[iter=10901]  loss = 0.2353\n",
      "[iter=11001]  loss = 0.2405\n",
      "[iter=11101]  loss = 0.2529\n",
      "[iter=11201]  loss = 0.2352\n",
      "[iter=11301]  loss = 0.2441\n",
      "[iter=11401]  loss = 0.2326\n",
      "[iter=11501]  loss = 0.2228\n",
      "[iter=11601]  loss = 0.2336\n",
      "[iter=11701]  loss = 0.2220\n",
      "[iter=11801]  loss = 0.2300\n",
      "[iter=11901]  loss = 0.2307\n",
      "[iter=12001]  loss = 0.2299\n",
      "[iter=12101]  loss = 0.2297\n",
      "[iter=12201]  loss = 0.2313\n",
      "[iter=12301]  loss = 0.2385\n",
      "[iter=12401]  loss = 0.2340\n",
      "[iter=12501]  loss = 0.2349\n",
      "[iter=12601]  loss = 0.2371\n",
      "[iter=12701]  loss = 0.2256\n",
      "[iter=12801]  loss = 0.2355\n",
      "[iter=12901]  loss = 0.2349\n",
      "[iter=13001]  loss = 0.2244\n",
      "[iter=13101]  loss = 0.2326\n",
      "[iter=13201]  loss = 0.2454\n",
      "[iter=13301]  loss = 0.2348\n",
      "[iter=13401]  loss = 0.2259\n",
      "[iter=13501]  loss = 0.2271\n",
      "[iter=13601]  loss = 0.2352\n",
      "[iter=13701]  loss = 0.2303\n",
      "[iter=13801]  loss = 0.2238\n",
      "[iter=13901]  loss = 0.2353\n",
      "[iter=14001]  loss = 0.2282\n",
      "[iter=14101]  loss = 0.2233\n",
      "[iter=14201]  loss = 0.2323\n",
      "[iter=14301]  loss = 0.2265\n",
      "[iter=14401]  loss = 0.2294\n",
      "[iter=14501]  loss = 0.2209\n",
      "[iter=14601]  loss = 0.2289\n",
      "[iter=14701]  loss = 0.2299\n",
      "[iter=14801]  loss = 0.2251\n",
      "[iter=14901]  loss = 0.2295\n",
      "[iter=15001]  loss = 0.2293\n",
      "[iter=15101]  loss = 0.2328\n",
      "[iter=15201]  loss = 0.2238\n",
      "[iter=15301]  loss = 0.2238\n",
      "[iter=15401]  loss = 0.2214\n",
      "[iter=15501]  loss = 0.2285\n",
      "[iter=15601]  loss = 0.2244\n",
      "[iter=15701]  loss = 0.2238\n",
      "[iter=15801]  loss = 0.2282\n",
      "[iter=15901]  loss = 0.2226\n",
      "[iter=16001]  loss = 0.2182\n",
      "[iter=16101]  loss = 0.2244\n",
      "[iter=16201]  loss = 0.2262\n",
      "[iter=16301]  loss = 0.2223\n",
      "[iter=16401]  loss = 0.2217\n",
      "[iter=16501]  loss = 0.2266\n",
      "[iter=16601]  loss = 0.2253\n",
      "[iter=16701]  loss = 0.2230\n",
      "[iter=16801]  loss = 0.2263\n",
      "[iter=16901]  loss = 0.2244\n",
      "[iter=17001]  loss = 0.2249\n",
      "[iter=17101]  loss = 0.2297\n",
      "[iter=17201]  loss = 0.2240\n",
      "[iter=17301]  loss = 0.2180\n",
      "[iter=17401]  loss = 0.2237\n",
      "[iter=17501]  loss = 0.2228\n",
      "[iter=17601]  loss = 0.2262\n",
      "[iter=17701]  loss = 0.2260\n",
      "[iter=17801]  loss = 0.2258\n",
      "[iter=17901]  loss = 0.2182\n",
      "[iter=18001]  loss = 0.2276\n",
      "[iter=18101]  loss = 0.2243\n",
      "[iter=18201]  loss = 0.2215\n",
      "[iter=18301]  loss = 0.2245\n",
      "[iter=18401]  loss = 0.2280\n",
      "[iter=18501]  loss = 0.2265\n",
      "[iter=18601]  loss = 0.2242\n",
      "[iter=18701]  loss = 0.2154\n",
      "[iter=18801]  loss = 0.2268\n",
      "[iter=18901]  loss = 0.2221\n",
      "[iter=19001]  loss = 0.2246\n",
      "[iter=19101]  loss = 0.2241\n",
      "[iter=19201]  loss = 0.2215\n",
      "[iter=19301]  loss = 0.2260\n",
      "[iter=19401]  loss = 0.2205\n",
      "[iter=19501]  loss = 0.2251\n",
      "[iter=19601]  loss = 0.2233\n",
      "[iter=19701]  loss = 0.2208\n",
      "[iter=19801]  loss = 0.2218\n",
      "[iter=19901]  loss = 0.2275\n",
      "[iter=20001]  loss = 0.2196\n",
      "[iter=20101]  loss = 0.2230\n",
      "[iter=20201]  loss = 0.2233\n",
      "[iter=20301]  loss = 0.2278\n",
      "[iter=20401]  loss = 0.2190\n",
      "[iter=20501]  loss = 0.2185\n",
      "[iter=20601]  loss = 0.2269\n",
      "[iter=20701]  loss = 0.2232\n",
      "[iter=20801]  loss = 0.2227\n",
      "[iter=20901]  loss = 0.2195\n",
      "[iter=21001]  loss = 0.2201\n",
      "[iter=21101]  loss = 0.2214\n",
      "[iter=21201]  loss = 0.2213\n",
      "[iter=21301]  loss = 0.2227\n",
      "[iter=21401]  loss = 0.2227\n",
      "[iter=21501]  loss = 0.2229\n",
      "[iter=21601]  loss = 0.2233\n",
      "[iter=21701]  loss = 0.2246\n",
      "[iter=21801]  loss = 0.2252\n",
      "[iter=21901]  loss = 0.2220\n",
      "[iter=22001]  loss = 0.2210\n",
      "[iter=22101]  loss = 0.2240\n",
      "[iter=22201]  loss = 0.2212\n",
      "[iter=22301]  loss = 0.2211\n",
      "[iter=22401]  loss = 0.2197\n",
      "[iter=22501]  loss = 0.2248\n",
      "[iter=22601]  loss = 0.2220\n",
      "[iter=22701]  loss = 0.2205\n",
      "[iter=22801]  loss = 0.2217\n",
      "[iter=22901]  loss = 0.2225\n",
      "[iter=23001]  loss = 0.2203\n",
      "[iter=23101]  loss = 0.2233\n",
      "[iter=23201]  loss = 0.2238\n",
      "[iter=23301]  loss = 0.2245\n",
      "[iter=23401]  loss = 0.2207\n",
      "[iter=23501]  loss = 0.2217\n",
      "[iter=23601]  loss = 0.2197\n",
      "[iter=23701]  loss = 0.2247\n",
      "[iter=23801]  loss = 0.2250\n",
      "[iter=23901]  loss = 0.2243\n",
      "[iter=24001]  loss = 0.2231\n",
      "[iter=24101]  loss = 0.2200\n",
      "[iter=24201]  loss = 0.2241\n",
      "[iter=24301]  loss = 0.2201\n",
      "[iter=24401]  loss = 0.2204\n",
      "[iter=24501]  loss = 0.2196\n",
      "[iter=24601]  loss = 0.2217\n",
      "[iter=24701]  loss = 0.2208\n",
      "[iter=24801]  loss = 0.2212\n",
      "[iter=24901]  loss = 0.2202\n",
      "[iter=25001]  loss = 0.2231\n",
      "[iter=25101]  loss = 0.2238\n",
      "[iter=25201]  loss = 0.2231\n",
      "[iter=25301]  loss = 0.2236\n",
      "[iter=25401]  loss = 0.2207\n",
      "[iter=25501]  loss = 0.2218\n",
      "[iter=25601]  loss = 0.2235\n",
      "[iter=25701]  loss = 0.2235\n",
      "[iter=25801]  loss = 0.2211\n",
      "[iter=25901]  loss = 0.2221\n",
      "[iter=26001]  loss = 0.2221\n",
      "[iter=26101]  loss = 0.2228\n",
      "[iter=26201]  loss = 0.2199\n",
      "[iter=26301]  loss = 0.2242\n",
      "[iter=26401]  loss = 0.2219\n",
      "[iter=26501]  loss = 0.2235\n",
      "[iter=26601]  loss = 0.2231\n",
      "[iter=26701]  loss = 0.2215\n",
      "[iter=26801]  loss = 0.2249\n",
      "[iter=26901]  loss = 0.2183\n",
      "[iter=27001]  loss = 0.2243\n",
      "[iter=27101]  loss = 0.2207\n",
      "[iter=27201]  loss = 0.2206\n",
      "[iter=27301]  loss = 0.2226\n",
      "[iter=27401]  loss = 0.2230\n",
      "[iter=27501]  loss = 0.2208\n",
      "[iter=27601]  loss = 0.2215\n",
      "[iter=27701]  loss = 0.2234\n",
      "[iter=27801]  loss = 0.2204\n",
      "[iter=27901]  loss = 0.2194\n",
      "[iter=28001]  loss = 0.2212\n",
      "[iter=28101]  loss = 0.2248\n",
      "[iter=28201]  loss = 0.2240\n",
      "[iter=28301]  loss = 0.2244\n",
      "[iter=28401]  loss = 0.2210\n",
      "[iter=28501]  loss = 0.2202\n",
      "[iter=28601]  loss = 0.2212\n",
      "[iter=28701]  loss = 0.2233\n",
      "[iter=28801]  loss = 0.2198\n",
      "[iter=28901]  loss = 0.2196\n",
      "[iter=29001]  loss = 0.2223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter=29101]  loss = 0.2241\n",
      "[iter=29201]  loss = 0.2246\n",
      "[iter=29301]  loss = 0.2221\n",
      "[iter=29401]  loss = 0.2224\n",
      "[iter=29501]  loss = 0.2211\n",
      "[iter=29601]  loss = 0.2211\n",
      "[iter=29701]  loss = 0.2207\n",
      "[iter=29801]  loss = 0.2242\n",
      "[iter=29901]  loss = 0.2232\n",
      "[iter=30001]  loss = 0.2215\n",
      "[iter=30101]  loss = 0.2205\n",
      "[iter=30201]  loss = 0.2186\n",
      "[iter=30301]  loss = 0.2228\n",
      "[iter=30401]  loss = 0.2222\n",
      "[iter=30501]  loss = 0.2240\n",
      "[iter=30601]  loss = 0.2248\n",
      "[iter=30701]  loss = 0.2215\n",
      "[iter=30801]  loss = 0.2227\n",
      "[iter=30901]  loss = 0.2221\n",
      "[iter=31001]  loss = 0.2231\n",
      "[iter=31101]  loss = 0.2241\n",
      "[iter=31201]  loss = 0.2235\n",
      "[iter=31301]  loss = 0.2229\n",
      "[iter=31401]  loss = 0.2226\n",
      "[iter=31501]  loss = 0.2242\n",
      "[iter=31601]  loss = 0.2199\n",
      "[iter=31701]  loss = 0.2221\n",
      "[iter=31801]  loss = 0.2227\n",
      "[iter=31901]  loss = 0.2252\n",
      "[iter=32001]  loss = 0.2217\n",
      "[iter=32101]  loss = 0.2217\n",
      "[iter=32201]  loss = 0.2229\n",
      "[iter=32301]  loss = 0.2234\n",
      "[iter=32401]  loss = 0.2198\n",
      "[iter=32501]  loss = 0.2247\n",
      "[iter=32601]  loss = 0.2201\n",
      "[iter=32701]  loss = 0.2249\n",
      "[iter=32801]  loss = 0.2206\n",
      "[iter=32901]  loss = 0.2227\n",
      "[iter=33001]  loss = 0.2263\n",
      "[iter=33101]  loss = 0.2247\n",
      "[iter=33201]  loss = 0.2228\n",
      "[iter=33301]  loss = 0.2208\n",
      "[iter=33401]  loss = 0.2242\n",
      "[iter=33501]  loss = 0.2209\n",
      "[iter=33601]  loss = 0.2225\n",
      "[iter=33701]  loss = 0.2217\n",
      "[iter=33801]  loss = 0.2239\n",
      "[iter=33901]  loss = 0.2222\n",
      "[iter=34001]  loss = 0.2207\n",
      "[iter=34101]  loss = 0.2192\n",
      "[iter=34201]  loss = 0.2230\n",
      "[iter=34301]  loss = 0.2248\n",
      "[iter=34401]  loss = 0.2223\n",
      "[iter=34501]  loss = 0.2228\n",
      "[iter=34601]  loss = 0.2222\n",
      "[iter=34701]  loss = 0.2235\n",
      "[iter=34801]  loss = 0.2222\n",
      "[iter=34901]  loss = 0.2224\n",
      "[iter=35001]  loss = 0.2200\n",
      "[iter=35101]  loss = 0.2247\n",
      "[iter=35201]  loss = 0.2241\n",
      "[iter=35301]  loss = 0.2230\n",
      "[iter=35401]  loss = 0.2231\n",
      "[iter=35501]  loss = 0.2212\n",
      "[iter=35601]  loss = 0.2244\n",
      "[iter=35701]  loss = 0.2235\n",
      "[iter=35801]  loss = 0.2204\n",
      "[iter=35901]  loss = 0.2222\n",
      "[iter=36001]  loss = 0.2211\n",
      "[iter=36101]  loss = 0.2228\n",
      "[iter=36201]  loss = 0.2211\n",
      "[iter=36301]  loss = 0.2229\n",
      "[iter=36401]  loss = 0.2213\n",
      "[iter=36501]  loss = 0.2226\n",
      "[iter=36601]  loss = 0.2238\n",
      "[iter=36701]  loss = 0.2220\n",
      "[iter=36801]  loss = 0.2262\n",
      "[iter=36901]  loss = 0.2222\n",
      "[iter=37001]  loss = 0.2220\n",
      "[iter=37101]  loss = 0.2248\n",
      "[iter=37201]  loss = 0.2241\n",
      "[iter=37301]  loss = 0.2252\n",
      "[iter=37401]  loss = 0.2223\n",
      "[iter=37501]  loss = 0.2234\n",
      "[iter=37601]  loss = 0.2220\n",
      "[iter=37701]  loss = 0.2222\n",
      "[iter=37801]  loss = 0.2214\n",
      "[iter=37901]  loss = 0.2213\n",
      "[iter=38001]  loss = 0.2218\n",
      "[iter=38101]  loss = 0.2236\n",
      "[iter=38201]  loss = 0.2237\n",
      "[iter=38301]  loss = 0.2231\n",
      "[iter=38401]  loss = 0.2213\n",
      "[iter=38501]  loss = 0.2230\n",
      "[iter=38601]  loss = 0.2214\n",
      "[iter=38701]  loss = 0.2239\n",
      "[iter=38801]  loss = 0.2228\n",
      "[iter=38901]  loss = 0.2216\n",
      "[iter=39001]  loss = 0.2225\n",
      "[iter=39101]  loss = 0.2231\n",
      "[iter=39201]  loss = 0.2240\n",
      "[iter=39301]  loss = 0.2230\n",
      "[iter=39401]  loss = 0.2238\n",
      "[iter=39501]  loss = 0.2236\n",
      "[iter=39601]  loss = 0.2212\n",
      "[iter=39701]  loss = 0.2242\n",
      "[iter=39801]  loss = 0.2208\n",
      "[iter=39901]  loss = 0.2230\n",
      "\n",
      "\n",
      "all variables: {'xc', 'xd', 'xb', 'xa', 'xw'}\n",
      "\n",
      "\n",
      "learnable params: ['ab', 'bc', 'cd', 'ac']\n",
      "\n",
      "\n",
      "dependencies: {'xw': ['xa', 'xb', 'xc', 'xd']}\n",
      "\n",
      "\n",
      "expressions dict: {'xw': 'ab*xa+bc*xb+cd*xc+ac*xd'}\n",
      "\n",
      "\n",
      "independent vars: ['xc', 'xd', 'xb', 'xa']\n",
      "\n",
      "\n",
      "leads_to dictionary: {'xc': {'xw'}, 'xd': {'xw'}, 'xb': {'xw'}, 'xa': {'xw'}, 'xw': set()}\n",
      "[iter=1]  loss = 0.0027\n",
      "[iter=101]  loss = 0.2874\n",
      "[iter=201]  loss = 0.2716\n",
      "[iter=301]  loss = 0.2921\n",
      "[iter=401]  loss = 0.2834\n",
      "[iter=501]  loss = 0.2715\n",
      "[iter=601]  loss = 0.2727\n",
      "[iter=701]  loss = 0.2656\n",
      "[iter=801]  loss = 0.2679\n",
      "[iter=901]  loss = 0.2700\n",
      "[iter=1001]  loss = 0.2675\n",
      "[iter=1101]  loss = 0.2659\n",
      "[iter=1201]  loss = 0.2707\n",
      "[iter=1301]  loss = 0.2631\n",
      "[iter=1401]  loss = 0.2720\n",
      "[iter=1501]  loss = 0.2677\n",
      "[iter=1601]  loss = 0.2602\n",
      "[iter=1701]  loss = 0.2625\n",
      "[iter=1801]  loss = 0.2570\n",
      "[iter=1901]  loss = 0.2720\n",
      "[iter=2001]  loss = 0.2677\n",
      "[iter=2101]  loss = 0.2646\n",
      "[iter=2201]  loss = 0.2582\n",
      "[iter=2301]  loss = 0.2664\n",
      "[iter=2401]  loss = 0.2564\n",
      "[iter=2501]  loss = 0.2537\n",
      "[iter=2601]  loss = 0.2637\n",
      "[iter=2701]  loss = 0.2566\n",
      "[iter=2801]  loss = 0.2532\n",
      "[iter=2901]  loss = 0.2737\n",
      "[iter=3001]  loss = 0.2619\n",
      "[iter=3101]  loss = 0.2528\n",
      "[iter=3201]  loss = 0.2563\n",
      "[iter=3301]  loss = 0.2621\n",
      "[iter=3401]  loss = 0.2633\n",
      "[iter=3501]  loss = 0.2514\n",
      "[iter=3601]  loss = 0.2590\n",
      "[iter=3701]  loss = 0.2610\n",
      "[iter=3801]  loss = 0.2476\n",
      "[iter=3901]  loss = 0.2616\n",
      "[iter=4001]  loss = 0.2563\n",
      "[iter=4101]  loss = 0.2568\n",
      "[iter=4201]  loss = 0.2471\n",
      "[iter=4301]  loss = 0.2498\n",
      "[iter=4401]  loss = 0.2527\n",
      "[iter=4501]  loss = 0.2556\n",
      "[iter=4601]  loss = 0.2442\n",
      "[iter=4701]  loss = 0.2580\n",
      "[iter=4801]  loss = 0.2438\n",
      "[iter=4901]  loss = 0.2460\n",
      "[iter=5001]  loss = 0.2419\n",
      "[iter=5101]  loss = 0.2470\n",
      "[iter=5201]  loss = 0.2480\n",
      "[iter=5301]  loss = 0.2500\n",
      "[iter=5401]  loss = 0.2513\n",
      "[iter=5501]  loss = 0.2480\n",
      "[iter=5601]  loss = 0.2415\n",
      "[iter=5701]  loss = 0.2625\n",
      "[iter=5801]  loss = 0.2510\n",
      "[iter=5901]  loss = 0.2478\n",
      "[iter=6001]  loss = 0.2471\n",
      "[iter=6101]  loss = 0.2450\n",
      "[iter=6201]  loss = 0.2473\n",
      "[iter=6301]  loss = 0.2517\n",
      "[iter=6401]  loss = 0.2459\n",
      "[iter=6501]  loss = 0.2520\n",
      "[iter=6601]  loss = 0.2409\n",
      "[iter=6701]  loss = 0.2413\n",
      "[iter=6801]  loss = 0.2483\n",
      "[iter=6901]  loss = 0.2453\n",
      "[iter=7001]  loss = 0.2362\n",
      "[iter=7101]  loss = 0.2534\n",
      "[iter=7201]  loss = 0.2429\n",
      "[iter=7301]  loss = 0.2371\n",
      "[iter=7401]  loss = 0.2383\n",
      "[iter=7501]  loss = 0.2357\n",
      "[iter=7601]  loss = 0.2480\n",
      "[iter=7701]  loss = 0.2503\n",
      "[iter=7801]  loss = 0.2458\n",
      "[iter=7901]  loss = 0.2475\n",
      "[iter=8001]  loss = 0.2376\n",
      "[iter=8101]  loss = 0.2389\n",
      "[iter=8201]  loss = 0.2436\n",
      "[iter=8301]  loss = 0.2409\n",
      "[iter=8401]  loss = 0.2399\n",
      "[iter=8501]  loss = 0.2422\n",
      "[iter=8601]  loss = 0.2393\n",
      "[iter=8701]  loss = 0.2408\n",
      "[iter=8801]  loss = 0.2380\n",
      "[iter=8901]  loss = 0.2326\n",
      "[iter=9001]  loss = 0.2361\n",
      "[iter=9101]  loss = 0.2385\n",
      "[iter=9201]  loss = 0.2360\n",
      "[iter=9301]  loss = 0.2374\n",
      "[iter=9401]  loss = 0.2357\n",
      "[iter=9501]  loss = 0.2397\n",
      "[iter=9601]  loss = 0.2354\n",
      "[iter=9701]  loss = 0.2380\n",
      "[iter=9801]  loss = 0.2298\n",
      "[iter=9901]  loss = 0.2385\n",
      "[iter=10001]  loss = 0.2369\n",
      "[iter=10101]  loss = 0.2375\n",
      "[iter=10201]  loss = 0.2352\n",
      "[iter=10301]  loss = 0.2372\n",
      "[iter=10401]  loss = 0.2380\n",
      "[iter=10501]  loss = 0.2335\n",
      "[iter=10601]  loss = 0.2404\n",
      "[iter=10701]  loss = 0.2378\n",
      "[iter=10801]  loss = 0.2341\n",
      "[iter=10901]  loss = 0.2351\n",
      "[iter=11001]  loss = 0.2349\n",
      "[iter=11101]  loss = 0.2405\n",
      "[iter=11201]  loss = 0.2354\n",
      "[iter=11301]  loss = 0.2280\n",
      "[iter=11401]  loss = 0.2442\n",
      "[iter=11501]  loss = 0.2344\n",
      "[iter=11601]  loss = 0.2383\n",
      "[iter=11701]  loss = 0.2356\n",
      "[iter=11801]  loss = 0.2326\n",
      "[iter=11901]  loss = 0.2356\n",
      "[iter=12001]  loss = 0.2338\n",
      "[iter=12101]  loss = 0.2344\n",
      "[iter=12201]  loss = 0.2353\n",
      "[iter=12301]  loss = 0.2290\n",
      "[iter=12401]  loss = 0.2365\n",
      "[iter=12501]  loss = 0.2344\n",
      "[iter=12601]  loss = 0.2356\n",
      "[iter=12701]  loss = 0.2344\n",
      "[iter=12801]  loss = 0.2338\n",
      "[iter=12901]  loss = 0.2345\n",
      "[iter=13001]  loss = 0.2313\n",
      "[iter=13101]  loss = 0.2286\n",
      "[iter=13201]  loss = 0.2347\n",
      "[iter=13301]  loss = 0.2303\n",
      "[iter=13401]  loss = 0.2266\n",
      "[iter=13501]  loss = 0.2375\n",
      "[iter=13601]  loss = 0.2329\n",
      "[iter=13701]  loss = 0.2283\n",
      "[iter=13801]  loss = 0.2295\n",
      "[iter=13901]  loss = 0.2384\n",
      "[iter=14001]  loss = 0.2321\n",
      "[iter=14101]  loss = 0.2374\n",
      "[iter=14201]  loss = 0.2312\n",
      "[iter=14301]  loss = 0.2352\n",
      "[iter=14401]  loss = 0.2314\n",
      "[iter=14501]  loss = 0.2311\n",
      "[iter=14601]  loss = 0.2330\n",
      "[iter=14701]  loss = 0.2301\n",
      "[iter=14801]  loss = 0.2273\n",
      "[iter=14901]  loss = 0.2323\n",
      "[iter=15001]  loss = 0.2316\n",
      "[iter=15101]  loss = 0.2366\n",
      "[iter=15201]  loss = 0.2355\n",
      "[iter=15301]  loss = 0.2300\n",
      "[iter=15401]  loss = 0.2325\n",
      "[iter=15501]  loss = 0.2272\n",
      "[iter=15601]  loss = 0.2289\n",
      "[iter=15701]  loss = 0.2322\n",
      "[iter=15801]  loss = 0.2340\n",
      "[iter=15901]  loss = 0.2239\n",
      "[iter=16001]  loss = 0.2285\n",
      "[iter=16101]  loss = 0.2302\n",
      "[iter=16201]  loss = 0.2337\n",
      "[iter=16301]  loss = 0.2288\n",
      "[iter=16401]  loss = 0.2297\n",
      "[iter=16501]  loss = 0.2305\n",
      "[iter=16601]  loss = 0.2268\n",
      "[iter=16701]  loss = 0.2308\n",
      "[iter=16801]  loss = 0.2291\n",
      "[iter=16901]  loss = 0.2367\n",
      "[iter=17001]  loss = 0.2267\n",
      "[iter=17101]  loss = 0.2323\n",
      "[iter=17201]  loss = 0.2321\n",
      "[iter=17301]  loss = 0.2300\n",
      "[iter=17401]  loss = 0.2329\n",
      "[iter=17501]  loss = 0.2309\n",
      "[iter=17601]  loss = 0.2326\n",
      "[iter=17701]  loss = 0.2315\n",
      "[iter=17801]  loss = 0.2308\n",
      "[iter=17901]  loss = 0.2327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter=18001]  loss = 0.2349\n",
      "[iter=18101]  loss = 0.2307\n",
      "[iter=18201]  loss = 0.2342\n",
      "[iter=18301]  loss = 0.2304\n",
      "[iter=18401]  loss = 0.2321\n",
      "[iter=18501]  loss = 0.2321\n",
      "[iter=18601]  loss = 0.2307\n",
      "[iter=18701]  loss = 0.2285\n",
      "[iter=18801]  loss = 0.2346\n",
      "[iter=18901]  loss = 0.2364\n",
      "[iter=19001]  loss = 0.2326\n",
      "[iter=19101]  loss = 0.2312\n",
      "[iter=19201]  loss = 0.2311\n",
      "[iter=19301]  loss = 0.2344\n",
      "[iter=19401]  loss = 0.2304\n",
      "[iter=19501]  loss = 0.2304\n",
      "[iter=19601]  loss = 0.2313\n",
      "[iter=19701]  loss = 0.2310\n",
      "[iter=19801]  loss = 0.2305\n",
      "[iter=19901]  loss = 0.2285\n",
      "[iter=20001]  loss = 0.2306\n",
      "[iter=20101]  loss = 0.2322\n",
      "[iter=20201]  loss = 0.2290\n",
      "[iter=20301]  loss = 0.2306\n",
      "[iter=20401]  loss = 0.2306\n",
      "[iter=20501]  loss = 0.2269\n",
      "[iter=20601]  loss = 0.2294\n",
      "[iter=20701]  loss = 0.2324\n",
      "[iter=20801]  loss = 0.2306\n",
      "[iter=20901]  loss = 0.2333\n",
      "[iter=21001]  loss = 0.2278\n",
      "[iter=21101]  loss = 0.2293\n",
      "[iter=21201]  loss = 0.2307\n",
      "[iter=21301]  loss = 0.2305\n",
      "[iter=21401]  loss = 0.2304\n",
      "[iter=21501]  loss = 0.2313\n",
      "[iter=21601]  loss = 0.2324\n",
      "[iter=21701]  loss = 0.2299\n",
      "[iter=21801]  loss = 0.2323\n",
      "[iter=21901]  loss = 0.2334\n",
      "[iter=22001]  loss = 0.2315\n",
      "[iter=22101]  loss = 0.2328\n",
      "[iter=22201]  loss = 0.2311\n",
      "[iter=22301]  loss = 0.2318\n",
      "[iter=22401]  loss = 0.2311\n",
      "[iter=22501]  loss = 0.2330\n",
      "[iter=22601]  loss = 0.2335\n",
      "[iter=22701]  loss = 0.2294\n",
      "[iter=22801]  loss = 0.2300\n",
      "[iter=22901]  loss = 0.2320\n",
      "[iter=23001]  loss = 0.2312\n",
      "[iter=23101]  loss = 0.2297\n",
      "[iter=23201]  loss = 0.2302\n",
      "[iter=23301]  loss = 0.2309\n",
      "[iter=23401]  loss = 0.2305\n",
      "[iter=23501]  loss = 0.2325\n",
      "[iter=23601]  loss = 0.2299\n",
      "[iter=23701]  loss = 0.2319\n",
      "[iter=23801]  loss = 0.2327\n",
      "[iter=23901]  loss = 0.2304\n",
      "[iter=24001]  loss = 0.2317\n",
      "[iter=24101]  loss = 0.2293\n",
      "[iter=24201]  loss = 0.2304\n",
      "[iter=24301]  loss = 0.2303\n",
      "[iter=24401]  loss = 0.2317\n",
      "[iter=24501]  loss = 0.2303\n",
      "[iter=24601]  loss = 0.2307\n",
      "[iter=24701]  loss = 0.2303\n",
      "[iter=24801]  loss = 0.2339\n",
      "[iter=24901]  loss = 0.2310\n",
      "[iter=25001]  loss = 0.2300\n",
      "[iter=25101]  loss = 0.2287\n",
      "[iter=25201]  loss = 0.2321\n",
      "[iter=25301]  loss = 0.2301\n",
      "[iter=25401]  loss = 0.2305\n",
      "[iter=25501]  loss = 0.2316\n",
      "[iter=25601]  loss = 0.2304\n",
      "[iter=25701]  loss = 0.2324\n",
      "[iter=25801]  loss = 0.2305\n",
      "[iter=25901]  loss = 0.2321\n",
      "[iter=26001]  loss = 0.2320\n",
      "[iter=26101]  loss = 0.2305\n",
      "[iter=26201]  loss = 0.2325\n",
      "[iter=26301]  loss = 0.2293\n",
      "[iter=26401]  loss = 0.2320\n",
      "[iter=26501]  loss = 0.2305\n",
      "[iter=26601]  loss = 0.2289\n",
      "[iter=26701]  loss = 0.2318\n",
      "[iter=26801]  loss = 0.2316\n",
      "[iter=26901]  loss = 0.2328\n",
      "[iter=27001]  loss = 0.2300\n",
      "[iter=27101]  loss = 0.2317\n",
      "[iter=27201]  loss = 0.2314\n",
      "[iter=27301]  loss = 0.2308\n",
      "[iter=27401]  loss = 0.2318\n",
      "[iter=27501]  loss = 0.2320\n",
      "[iter=27601]  loss = 0.2320\n",
      "[iter=27701]  loss = 0.2318\n",
      "[iter=27801]  loss = 0.2325\n",
      "[iter=27901]  loss = 0.2311\n",
      "[iter=28001]  loss = 0.2326\n",
      "[iter=28101]  loss = 0.2317\n",
      "[iter=28201]  loss = 0.2319\n",
      "[iter=28301]  loss = 0.2340\n",
      "[iter=28401]  loss = 0.2295\n",
      "[iter=28501]  loss = 0.2316\n",
      "[iter=28601]  loss = 0.2294\n",
      "[iter=28701]  loss = 0.2322\n",
      "[iter=28801]  loss = 0.2320\n",
      "[iter=28901]  loss = 0.2313\n",
      "[iter=29001]  loss = 0.2310\n",
      "[iter=29101]  loss = 0.2311\n",
      "[iter=29201]  loss = 0.2294\n",
      "[iter=29301]  loss = 0.2296\n",
      "[iter=29401]  loss = 0.2313\n",
      "[iter=29501]  loss = 0.2314\n",
      "[iter=29601]  loss = 0.2335\n",
      "[iter=29701]  loss = 0.2304\n",
      "[iter=29801]  loss = 0.2291\n",
      "[iter=29901]  loss = 0.2327\n",
      "[iter=30001]  loss = 0.2296\n",
      "[iter=30101]  loss = 0.2309\n",
      "[iter=30201]  loss = 0.2298\n",
      "[iter=30301]  loss = 0.2316\n",
      "[iter=30401]  loss = 0.2329\n",
      "[iter=30501]  loss = 0.2301\n",
      "[iter=30601]  loss = 0.2326\n",
      "[iter=30701]  loss = 0.2338\n",
      "[iter=30801]  loss = 0.2324\n",
      "[iter=30901]  loss = 0.2328\n",
      "[iter=31001]  loss = 0.2315\n",
      "[iter=31101]  loss = 0.2314\n",
      "[iter=31201]  loss = 0.2324\n",
      "[iter=31301]  loss = 0.2315\n",
      "[iter=31401]  loss = 0.2321\n",
      "[iter=31501]  loss = 0.2305\n",
      "[iter=31601]  loss = 0.2314\n",
      "[iter=31701]  loss = 0.2308\n",
      "[iter=31801]  loss = 0.2314\n",
      "[iter=31901]  loss = 0.2319\n",
      "[iter=32001]  loss = 0.2322\n",
      "[iter=32101]  loss = 0.2297\n",
      "[iter=32201]  loss = 0.2301\n",
      "[iter=32301]  loss = 0.2326\n",
      "[iter=32401]  loss = 0.2323\n",
      "[iter=32501]  loss = 0.2310\n",
      "[iter=32601]  loss = 0.2317\n",
      "[iter=32701]  loss = 0.2320\n",
      "[iter=32801]  loss = 0.2310\n",
      "[iter=32901]  loss = 0.2324\n",
      "[iter=33001]  loss = 0.2296\n",
      "[iter=33101]  loss = 0.2298\n",
      "[iter=33201]  loss = 0.2322\n",
      "[iter=33301]  loss = 0.2331\n",
      "[iter=33401]  loss = 0.2325\n",
      "[iter=33501]  loss = 0.2307\n",
      "[iter=33601]  loss = 0.2298\n",
      "[iter=33701]  loss = 0.2319\n",
      "[iter=33801]  loss = 0.2305\n",
      "[iter=33901]  loss = 0.2323\n",
      "[iter=34001]  loss = 0.2317\n",
      "[iter=34101]  loss = 0.2329\n",
      "[iter=34201]  loss = 0.2310\n",
      "[iter=34301]  loss = 0.2317\n",
      "[iter=34401]  loss = 0.2312\n",
      "[iter=34501]  loss = 0.2324\n",
      "[iter=34601]  loss = 0.2332\n",
      "[iter=34701]  loss = 0.2316\n",
      "[iter=34801]  loss = 0.2312\n",
      "[iter=34901]  loss = 0.2319\n",
      "[iter=35001]  loss = 0.2316\n",
      "[iter=35101]  loss = 0.2318\n",
      "[iter=35201]  loss = 0.2315\n",
      "[iter=35301]  loss = 0.2322\n",
      "[iter=35401]  loss = 0.2314\n",
      "[iter=35501]  loss = 0.2309\n",
      "[iter=35601]  loss = 0.2320\n",
      "[iter=35701]  loss = 0.2321\n",
      "[iter=35801]  loss = 0.2317\n",
      "[iter=35901]  loss = 0.2315\n",
      "[iter=36001]  loss = 0.2323\n",
      "[iter=36101]  loss = 0.2320\n",
      "[iter=36201]  loss = 0.2311\n",
      "[iter=36301]  loss = 0.2306\n",
      "[iter=36401]  loss = 0.2312\n",
      "[iter=36501]  loss = 0.2317\n",
      "[iter=36601]  loss = 0.2326\n",
      "[iter=36701]  loss = 0.2338\n",
      "[iter=36801]  loss = 0.2308\n",
      "[iter=36901]  loss = 0.2309\n",
      "[iter=37001]  loss = 0.2325\n",
      "[iter=37101]  loss = 0.2338\n",
      "[iter=37201]  loss = 0.2310\n",
      "[iter=37301]  loss = 0.2300\n",
      "[iter=37401]  loss = 0.2318\n",
      "[iter=37501]  loss = 0.2345\n",
      "[iter=37601]  loss = 0.2315\n",
      "[iter=37701]  loss = 0.2317\n",
      "[iter=37801]  loss = 0.2337\n",
      "[iter=37901]  loss = 0.2327\n",
      "[iter=38001]  loss = 0.2332\n",
      "[iter=38101]  loss = 0.2309\n",
      "[iter=38201]  loss = 0.2325\n",
      "[iter=38301]  loss = 0.2313\n",
      "[iter=38401]  loss = 0.2306\n",
      "[iter=38501]  loss = 0.2324\n",
      "[iter=38601]  loss = 0.2293\n",
      "[iter=38701]  loss = 0.2324\n",
      "[iter=38801]  loss = 0.2330\n",
      "[iter=38901]  loss = 0.2330\n",
      "[iter=39001]  loss = 0.2302\n",
      "[iter=39101]  loss = 0.2307\n",
      "[iter=39201]  loss = 0.2315\n",
      "[iter=39301]  loss = 0.2309\n",
      "[iter=39401]  loss = 0.2320\n",
      "[iter=39501]  loss = 0.2315\n",
      "[iter=39601]  loss = 0.2330\n",
      "[iter=39701]  loss = 0.2315\n",
      "[iter=39801]  loss = 0.2320\n",
      "[iter=39901]  loss = 0.2312\n"
     ]
    }
   ],
   "source": [
    "cgp.parse_expressions()\n",
    "training_data = cgp.gen_training_data()\n",
    "loss_running_record_mu = cgp.run_training_loop_one_neuron_model( training_data )\n",
    "\n",
    "cgp_original.parse_expressions()\n",
    "training_data = cgp_original.gen_training_data()\n",
    "loss_running_record = cgp_original.run_training_loop_one_neuron_model( training_data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c543157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2, 0.3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()     \n",
    "plt.plot(loss_running_record_mu, color=\"red\") \n",
    "plt.plot(loss_running_record)\n",
    "plt.ylim(0.2,0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb704170",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
